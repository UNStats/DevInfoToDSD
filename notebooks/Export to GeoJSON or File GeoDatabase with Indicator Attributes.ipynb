{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to GeoJSON with Indicator Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook will walk you through the process of converting your DevInfo database into the possible output formats of:\n",
    "- GeoJSON (only spatial information and a reference area id)\n",
    "- GeoJSON (full attribute AND spatial information)\n",
    "- *TODO ::: Add link to Notebook for Exporting from GeoJSON (this) to FileGeodatabase*\n",
    "\n",
    "### **Important**\n",
    "\n",
    "You need to have previously run the Export to Shapefiles notebook **before** running this notebook as it will need a folder location of the individual shapefiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the needed python libraries\n",
    "install the GDAL pythyon library (ogr import below) by opening the anaconda prompt and using `conda install gdal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pyodbc\n",
    "from osgeo import ogr\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# location of access database\n",
    "access_database = r'Z:\\dev\\nepal-import\\NepalInfo2016_for_python.accdb'\n",
    "\n",
    "# where is your working folder? usually just the name of the country you are working on\n",
    "output_base = 'nepal'\n",
    "\n",
    "# location of individual shapefiles for each layer. \n",
    "# this is created by running the Export to Shapefiles jupyter notebook, see *Important* note above\n",
    "output_shapes_folder = 'shapes'\n",
    "\n",
    "# where do you want to write the output geojson files?\n",
    "output_geojson_folder = 'geojson_full'\n",
    "\n",
    "# flag for full properties & geometries\n",
    "# True for full attributes and geometry\n",
    "# False for only REF_AREA and REF_AREA_ID and geometry\n",
    "full_props = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for the `Esri Shapefile` driver\n",
    "The DevInfo Access database stores the geometry as a Shapefile. We can use this driver to read that into our script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esri Shapefile driver IS available.\n"
     ]
    }
   ],
   "source": [
    "shp_driver_lbl = 'Esri Shapefile'\n",
    "shp_driver = ogr.GetDriverByName(shp_driver_lbl)\n",
    "if shp_driver is None:\n",
    "    print ('{} driver not available.'.format(shp_driver_lbl))\n",
    "else:\n",
    "    print ('{} driver IS available.'.format(shp_driver_lbl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare to query the DevInfo Access Database\n",
    "Here we will map our DevInfo fields to the DSD as defined here. **TODO :: add link(s) to reference data schema**\n",
    "\n",
    "This is our ouptut data schema that will show in the GeoJSON `properties`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'DSD_FIELD' : 'DevInfoField'\n",
    "field_mappings = {\n",
    "    'INDICATOR_ID' : 'Indicator_NId',\n",
    "    'INDICATOR' : 'Indicator_Name',\n",
    "    'REF_AREA' : 'Area_Name',\n",
    "    'REF_AREA_ID' : 'Area_ID',\n",
    "    'OBS_VALUE' : 'Data_Value',\n",
    "    'UNIT_ID' : 'Unit_NId',\n",
    "    'UNIT' : 'Unit_Name',\n",
    "    'TIME_PERIOD' : 'TimePeriod'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the DevInfo Access Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sucessfully executed data query :: 124272 rows returned\n"
     ]
    }
   ],
   "source": [
    "connStr = (\n",
    "    r'Driver={{Microsoft Access Driver (*.mdb, *.accdb)}};'\n",
    "    r'DBQ={};'.format(access_database)\n",
    ")\n",
    "\n",
    "cnxn = pyodbc.connect(connStr)\n",
    "\n",
    "sql = \"\"\"\\\n",
    "SELECT UT_Data.Indicator_NId, UT_Indicator_en.Indicator_Name, UT_Data.Data_Value, UT_Unit_en.Unit_NId, UT_Unit_en.Unit_Name, UT_Area_en.Area_ID, UT_Area_en.Area_Name, UT_Area_Level_en.Area_Level_Name, UT_Area_en.Area_Level, UT_Indicator_Classifications_en.IC_Name, UT_Indicator_Classifications_en.Publisher, UT_TimePeriod.TimePeriod, UT_Subgroup_Vals_en.Subgroup_Val, UT_Subgroup_Type_en.Subgroup_Type_Name, UT_Area_Map_Layer.Layer_NId\n",
    "FROM ((((UT_Area_Map_Layer INNER JOIN ((UT_Area_Level_en INNER JOIN (UT_Subgroup_Vals_en INNER JOIN (UT_Unit_en INNER JOIN (UT_Indicator_en INNER JOIN (UT_Indicator_Unit_Subgroup INNER JOIN (UT_TimePeriod INNER JOIN (UT_Indicator_Classifications_en INNER JOIN (UT_Area_en INNER JOIN UT_Data ON UT_Area_en.[Area_NId] = UT_Data.[Area_NId]) ON UT_Indicator_Classifications_en.IC_NId = UT_Data.Source_NId) ON UT_TimePeriod.TimePeriod_NId = UT_Data.TimePeriod_NId) ON UT_Indicator_Unit_Subgroup.IUSNId = UT_Data.IUSNId) ON UT_Indicator_en.Indicator_NId = UT_Indicator_Unit_Subgroup.Indicator_NId) ON UT_Unit_en.Unit_NId = UT_Indicator_Unit_Subgroup.Unit_NId) ON UT_Subgroup_Vals_en.Subgroup_Val_NId = UT_Indicator_Unit_Subgroup.Subgroup_Val_NId) ON UT_Area_Level_en.Area_Level = UT_Area_en.Area_Level) INNER JOIN UT_Area_Map ON UT_Area_en.Area_NId = UT_Area_Map.Area_NId) ON UT_Area_Map_Layer.Layer_NId = UT_Area_Map.Layer_NId) INNER JOIN UT_Area_Map_Metadata_en ON UT_Area_Map_Layer.Layer_NId = UT_Area_Map_Metadata_en.Layer_NId) INNER JOIN UT_Subgroup_Vals_Subgroup ON UT_Subgroup_Vals_en.Subgroup_Val_NId = UT_Subgroup_Vals_Subgroup.Subgroup_Val_NId) INNER JOIN UT_Subgroup_en ON UT_Subgroup_Vals_Subgroup.Subgroup_NId = UT_Subgroup_en.Subgroup_NId) INNER JOIN UT_Subgroup_Type_en ON UT_Subgroup_en.Subgroup_Type = UT_Subgroup_Type_en.Subgroup_Type_NId\n",
    "ORDER BY UT_Data.Indicator_NId\n",
    "\"\"\"\n",
    "\n",
    "crsr = cnxn.execute(sql)\n",
    "\n",
    "rows = crsr.fetchall()\n",
    "\n",
    "print ('sucessfully executed data query :: {} rows returned'.format(len(rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk up the data\n",
    "Chunk up the data by Indicator. This will let us create one layer per Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done chunking data by indicator, by layer\n"
     ]
    }
   ],
   "source": [
    "chunks = {}\n",
    "for row in rows:\n",
    "    \n",
    "    ind_id = row.Indicator_NId\n",
    "    layer_id = row.Layer_NId\n",
    "    \n",
    "    if ind_id not in chunks:\n",
    "        chunks[ind_id] = {}\n",
    "    \n",
    "    if layer_id not in chunks[ind_id]:\n",
    "        chunks[ind_id][layer_id] = {}\n",
    "        chunks[ind_id][layer_id]['rows'] = []\n",
    "    \n",
    "    chunks[ind_id][layer_id]['rows'].append(row)\n",
    "\n",
    "print ('done chunking data by indicator, by layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the Attribute Data & Spatial Data\n",
    "Finally, we will step through our data to create individual geojson files for each layer, for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 15 features to indicator_4_0_layer_50.geojson\n",
      "writing 4 features to indicator_4_0_layer_51.geojson\n",
      "writing 5 features to indicator_4_0_layer_52.geojson\n",
      "writing 4 features to indicator_4_0_layer_48.geojson\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# store the already reference geometry in memory for faster recall\n",
    "geom_cache = {}\n",
    "\n",
    "for c in chunks:\n",
    "    # test with just one indicator\n",
    "    if c != 4:\n",
    "        continue\n",
    "    \n",
    "    ind = c\n",
    "    lyrs = chunks[c]\n",
    "\n",
    "    for lyr in lyrs:\n",
    "        feature_collection = {\n",
    "            'type' : 'FeatureCollection',\n",
    "            'features': []\n",
    "        }\n",
    "    \n",
    "        rows = lyrs[lyr]['rows']\n",
    "\n",
    "        for row in rows:\n",
    "            layer_id = row.Layer_NId\n",
    "            area_id = row.Area_ID\n",
    "            \n",
    "            # test with just one layer\n",
    "#             if layer_id != 52:\n",
    "#                 continue\n",
    "            \n",
    "            geom = None\n",
    "            if full_props:\n",
    "                if area_id not in geom_cache:\n",
    "                    # look for the already created shapefile\n",
    "                    shp_file_path = '{}/{}.shp'.format(os.path.join(output_base, output_shapes_folder), layer_id)\n",
    "\n",
    "                    # check to see if we were able to get the shapefile\n",
    "                    # TODO: add logging rather than just printing an exception\n",
    "                    shp_file = shp_driver.Open(shp_file_path)\n",
    "                    if shp_file is None:\n",
    "    #                     print ('{} shape file not found'.format(shp_file_path))\n",
    "                        continue\n",
    "\n",
    "                    layer = shp_file.GetLayer()\n",
    "                    \n",
    "                    where_clause = 'ID_ = \\'{}\\''.format(area_id)\n",
    "                    layer.SetAttributeFilter(where_clause)\n",
    "                    feature = layer.GetNextFeature()\n",
    "                    if feature is None:\n",
    "                        print ('unable to get feature for layer {} :: where {}'.format(layer_id, where_clause))\n",
    "                        continue\n",
    "                        \n",
    "                    geom_ref = feature.GetGeometryRef()\n",
    "\n",
    "                    geom_json_str = geom_ref.ExportToJson()\n",
    "\n",
    "                    geom = json.loads(geom_json_str)\n",
    "\n",
    "                    #store in cache\n",
    "                    geom_cache[area_id] = geom\n",
    "\n",
    "                    # clean up\n",
    "                    del feature\n",
    "                    del layer\n",
    "                    del shp_file\n",
    "\n",
    "                else:\n",
    "                    geom = geom_cache[area_id]\n",
    "    \n",
    "            # setup the new feature\n",
    "            feature = {\n",
    "                'properties': {},\n",
    "                'geometry': geom\n",
    "            }\n",
    "            \n",
    "            # if we are going to include full attributes and geometry\n",
    "            if full_props:\n",
    "                for field in field_mappings:\n",
    "                    feature['properties'][field] = getattr(row, field_mappings[field])\n",
    "            else:\n",
    "                feature['properties']['REF_AREA'] = getattr(row, field_mappings['REF_AREA'])\n",
    "                feature['properties']['REF_AREA_ID'] = getattr(row, field_mappings['REF_AREA_ID'])\n",
    "\n",
    "            feature_collection['features'].append(feature)\n",
    "        \n",
    "        # create filename for output geojson file\n",
    "        new_ind = str(c)\n",
    "        new_ind_id = new_ind.replace('.', '_')\n",
    "        layer_name = 'indicator_{}_layer_{}.geojson'.format(new_ind_id, layer_id)\n",
    "\n",
    "        # full path for the output geojson file\n",
    "        full_path = Path(os.path.join(output_base, output_geojson_folder, layer_name))    \n",
    "    \n",
    "        print ('writing {} features to {}'.format(len(feature_collection['features']), layer_name))\n",
    "        with open(full_path, 'w') as file:\n",
    "            file.write(json.dumps(feature_collection))\n",
    "\n",
    "del geom_cache\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
