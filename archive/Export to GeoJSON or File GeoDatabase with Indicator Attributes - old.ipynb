{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to GeoJSON or File GeoDatabase with Indicator Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook will walk you through the process of converting your DevInfo database into the possible output formats of:\n",
    "- GeoJSON (only spatial information and a reference area id)\n",
    "- GeoJSON (full attribute AND spatial information)\n",
    "- FileGeodatabase\n",
    "\n",
    "### **Important**\n",
    "\n",
    "You need to have previously run the Export to Shapefiles notebook **before** running this notebook as it will need a folder location of the individual shapefiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using the **[ArcPy](http://pro.arcgis.com/en/pro-app/arcpy/get-started/what-is-arcpy-.htm)** python library, we will need to start our Jupyter Notebook the following way:\n",
    "\n",
    "- Open ArcGIS Pro\n",
    "- Click the **Project** tab and click **Python** to access the **Python Package Manager**. To create, edit or remove environments click on the **Manage Environments** button.\n",
    "- Clone the existing default python environment as the default is read-only. *[reference](http://pro.arcgis.com/en/pro-app/arcpy/get-started/what-is-conda.htm#ESRI_SECTION2_1B154688AEE0497F836B3FFBAAAD0C8C)*\n",
    "- Find the `pyodbc` package in the list and install it. *[reference](http://pro.arcgis.com/en/pro-app/arcpy/get-started/what-is-conda.htm#ESRI_SECTION2_85BC919097434B3B9AE1A746D793AA29)*\n",
    "- **IMPORTANT** open the `Python Command Prompt` and verify the path is to your new, cloned enviornment\n",
    "- use the `cd <path>` command to change to your working directory\n",
    "- start your Jupyter Notebook server using the `jupyter notebook` command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the needed python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pyodbc\n",
    "import arcpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# location of access database\n",
    "access_database = r'Z:\\dev\\nepal-import\\NepalInfo2016_for_python.accdb'\n",
    "\n",
    "# where is your working folder? usually just the name of the country you are working on\n",
    "output_base = 'nepal'\n",
    "\n",
    "# location of individual shapefiles for each layer. \n",
    "# this is created by running the Export to Shapefiles jupyter notebook, see *Important* note above\n",
    "output_shapes_folder = 'shapes'\n",
    "\n",
    "# where do you want to write the output geojson files?\n",
    "output_geojson_folder = 'geojson_full'\n",
    "\n",
    "# we will need to create a fgdb anyway. \n",
    "# TODO: add a clean up to keep it or delete it based on this flag\n",
    "keep_fgdb = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create FileGeodatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spatial_out = 'output_fgdb'\n",
    "arcpy.CreateFileGDB_management(os.path.join(output_base, spatial_out), output_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the template feature class to our working area\n",
    "A template feature class will have the base fields we want all the new features to have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy fc template into new fgdb\n",
    "in_features = os.path.join('devinfo_templates.gdb', 'devinfo_fc_template')\n",
    "out_path = os.path.join(output_base, spatial_out, '{}.gdb'.format(output_base))\n",
    "out_template_name = '{}_fc_template'.format(output_base)\n",
    "\n",
    "template_path = os.path.join(out_path, out_template_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the template feature class in the working area if it doesn't already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if arcpy.Exists(template_path):\n",
    "    print ('template feature class already exists at :: {}'.format(template_path))\n",
    "else:\n",
    "    arcpy.FeatureClassToFeatureClass_conversion(in_features=in_features, out_path=out_path, out_name=out_template_name)\n",
    "    print ('succesfully created template feature class with fields :: {}'.format(template_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the DevInfo Access Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connStr = (\n",
    "    r'Driver={{Microsoft Access Driver (*.mdb, *.accdb)}};'\n",
    "    r'DBQ={};'.format(access_database)\n",
    ")\n",
    "\n",
    "cnxn = pyodbc.connect(connStr)\n",
    "\n",
    "sql = \"\"\"\\\n",
    "SELECT \n",
    "    Indicator_NId, \n",
    "    Indicator_Name,\n",
    "    Data_Value,\n",
    "    Unit_NId, \n",
    "    Unit_Name,\n",
    "    Subgroup_Val,\n",
    "    Subgroup_Type_Name,\n",
    "    TimePeriod,\n",
    "    Area_Level_Name,\n",
    "    Area_Level,\n",
    "    Area_ID,\n",
    "    Area_Name,\n",
    "    Layer_NId,\n",
    "    IC_Name,\n",
    "    Publisher\n",
    "FROM ut_data_query \n",
    "ORDER BY indicator_nid ASC\n",
    "\"\"\"\n",
    "crsr = cnxn.execute(sql)\n",
    "\n",
    "rows = crsr.fetchall()\n",
    "\n",
    "print ('sucessfully executed data query :: {} rows returned'.format(len(rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk up the data\n",
    "Chunk up the data by Indicator. This will let us create one layer per Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunks = {}\n",
    "for row in rows:\n",
    "    ind_id = row.Indicator_NId\n",
    "    if ind_id not in chunks:\n",
    "        chunks[ind_id] = {}\n",
    "        chunks[ind_id]['rows'] = []\n",
    "        \n",
    "    chunks[ind_id]['rows'].append(row)\n",
    "\n",
    "for c in chunks:\n",
    "    print (c, len(chunks[c]['rows']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the layers and insert the data\n",
    "For each Indicator, we want to create a new layer and add in *both* the attribute and the spatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "template_fields = [ 'SHAPE@', 'Indicator_NId', 'Indicator_Name', 'Data_Value', 'Unit_NId', 'Unit_Name', 'Subgroup_Val', 'Subgroup_Type_Name', 'TimePeriod', 'Area_Level_Name', 'Area_Level', 'Area_ID', 'Area_Name', 'Layer_NId', 'IC_Name', 'Publisher']\n",
    "\n",
    "# store the already reference geometry in memory for faster recall\n",
    "geom_cache = {}\n",
    "\n",
    "for c in chunks:\n",
    "    \n",
    "    # test with just one\n",
    "    # remove this if statement if you want to process all the indicators\n",
    "    if c != 21.0:\n",
    "        continue\n",
    "    \n",
    "    # for each indicator's \"chunk\" of rows..\n",
    "    rows = chunks[c]['rows']\n",
    "    for row in rows:\n",
    "        layer_id = row.Layer_NId\n",
    "        area_id = row.Area_ID\n",
    "\n",
    "        # look for the already created shapefile\n",
    "        shp_file_path = '{}/{}.shp'.format(os.path.join(output_base, output_shapes_folder), layer_id)\n",
    "\n",
    "        # check to see if we were able to get the shapefile\n",
    "        # TODO: add logging rather than just printing an exception\n",
    "        try:\n",
    "            desc = arcpy.Describe(shp_file_path)\n",
    "        except:\n",
    "            #print ('{} shape file not found'.format(shp_file_path))\n",
    "            continue\n",
    "\n",
    "        # create the layer name from the values in the row\n",
    "        indicator_id = row.Indicator_NId\n",
    "        new_ind = str(indicator_id)\n",
    "        new_ind_id = new_ind.replace('.', '_')\n",
    "        layer_name = 'indicator_{}_layer_{}'.format(new_ind_id, layer_id)\n",
    "        \n",
    "        # if the layer does not exist already, create it\n",
    "        full_path = os.path.join(out_path, layer_name)\n",
    "        if not arcpy.Exists(full_path):\n",
    "            arcpy.CreateFeatureclass_management(out_path, layer_name, 'POLYGON', template_path)\n",
    "            \n",
    "        # check the geometry cache to see if we can just grab it from memory\n",
    "        # if not, open up the shapefile and get the geometry\n",
    "        geom = None\n",
    "        if area_id in geom_cache:\n",
    "            geom = geom_cache[area_id]\n",
    "        else:\n",
    "            where_clause = '{} = \\'{}\\''.format(area_id_field, area_id)   \n",
    "            with arcpy.da.SearchCursor(shp_file_path, ['SHAPE@'], where_clause) as cursor:\n",
    "                for area_rows in cursor:\n",
    "                    geom = area_rows[0]\n",
    "                    geom_cache[area_id] = geom\n",
    "\n",
    "        # create the insert cursor used to actually insert the data\n",
    "        ic = arcpy.da.InsertCursor(full_path, template_fields)\n",
    "        \n",
    "        # convert the row object to a list\n",
    "        vals = list(row)\n",
    "        \n",
    "        # put the geometry value in the first position of the list\n",
    "        vals.insert(0, geom)\n",
    "                \n",
    "        # insert the row\n",
    "        ic.insertRow(vals)\n",
    "        \n",
    "        # clean up the insert cursor\n",
    "        del ic\n",
    "                \n",
    "# delete the geometry cache from memory\n",
    "del geom_cache\n",
    "print ('done creating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the FileGeodatabase to GeoJSON\n",
    "\n",
    "_exporting from a file geodatabse to geojson using the arcpy.FeaturesToJSON conversion throws a generic error. for now, manually create the geojson_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do you want all the fields or only the area id field\n",
    "include_all_fields = False\n",
    "\n",
    "# do you want to export the geometry \n",
    "include_geometry = True\n",
    "\n",
    "# tell arcpy where to look for the feature classes by setting the workspace\n",
    "arcpy.env.workspace = out_path\n",
    "\n",
    "# loop through each feature class\n",
    "for fc in arcpy.ListFeatureClasses():\n",
    "\n",
    "    # skip the template fc\n",
    "    if fc == out_template_name:\n",
    "        continue\n",
    "\n",
    "    # set the name of the output geojson file\n",
    "    out_geojson = '{}/{}.geojson'.format(os.path.join(output_base, output_geojson_folder), fc)\n",
    "\n",
    "    # Here is where arcpy throws a generic 999999 error. leave for reference and follow up\n",
    "    # arcpy.FeaturesToJSON_conversion(in_features=out_loc, out_json_file=out_geojson)\n",
    "\n",
    "    # base geojson template\n",
    "    template = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": []\n",
    "    }\n",
    "\n",
    "    print ('collecting geojson for {}'.format(out_geojson))\n",
    "\n",
    "    # loop through each feature and add it to the geojson template\n",
    "    with arcpy.da.SearchCursor(fc, template_fields) as cursor:\n",
    "        \n",
    "        # get a reference to the fields in the feature class\n",
    "        c_fields = cursor.fields\n",
    "        \n",
    "        # for reach row\n",
    "        for row in cursor:\n",
    "            \n",
    "            # get the geometry object\n",
    "            geom = row[c_fields.index('SHAPE@')]\n",
    "\n",
    "            #setup the base geojson feature\n",
    "            feature = {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {}\n",
    "            }\n",
    "            \n",
    "            # add geometry if specified\n",
    "            if include_geometry:\n",
    "                feature['geometry'] = geom.__geo_interface__\n",
    "\n",
    "            # add fields if specified\n",
    "            if include_all_fields:\n",
    "                for f in c_fields:\n",
    "                    # skip these fields in the output\n",
    "                    if f in ['SHAPE@', 'OBJECTID']:\n",
    "                        continue\n",
    "\n",
    "                    feature['properties'][f] = row[c_fields.index(f)]\n",
    "            else:\n",
    "                feature['properties']['REF_AREA_ID'] = row[c_fields.index('Area_ID')]\n",
    "\n",
    "            # add feature to base\n",
    "            template['features'].append(feature)\n",
    "\n",
    "    # create the geojson file on disk and write the data to it\n",
    "    with open(out_geojson, 'w') as file:\n",
    "        json.dump(template, file)\n",
    "\n",
    "    print ('succesfully wrote {}'.format(out_geojson))\n",
    "\n",
    "print ('done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
